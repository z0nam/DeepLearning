{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*해당 문서는 Jupyter notebook 이용해서 작성됨.\n",
    "\n",
    "- 경험상 Anaconda3로 한 방에 해결하는 것이 마음이 편함. 과학 계산 및 자료 분석에 필요한 각종 3rd party module들이 한꺼번에 설치되는 기적… (Python만 달랑 설치한 이후 하나씩 필요한 module을 다운받아서 깔려고 하면 굉장히 피곤해짐)\n",
    "\n",
    "\n",
    "- 링크: https://www.continuum.io/downloads  (Mac, Windows, Linux 각 버전 맞춰서 설치할 것.)\n",
    "\n",
    "\n",
    "- 윈도우에서 환경 변수 (environment path) 설정은 아래 문서를 참조http://dwfox.tistory.com/67 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##Python 내장 모듈인 urllib 라이브러리가 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test.png', <http.client.HTTPMessage at 0x1037f8208>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#urllib.request.urlretrieve(url, file): 웹 페이지 정보를 파일로 바로 저장.\n",
    "import urllib.request as req\n",
    "import os\n",
    "#저장 폴더(본인이 임의로 바꿀것)\n",
    "os.chdir(\".\")\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test.png\"\n",
    "req.urlretrieve(url, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장했습니다\n"
     ]
    }
   ],
   "source": [
    "#urllib.request.urlopen(): 데이터를 메모리에 올려놓은 뒤 저장하기\n",
    "mem = req.urlopen(url).read()\n",
    "with open(\"test2.png\", \"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"저장했습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*open에서 \"wb\"는 바이너리 모드로 write을 의미함. png파일이라 텍스트 형식이 아니기 때문."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##매개변수를 추가해 요청을 전송하기\n",
    "기상청 RSS: http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\n",
    "\n",
    "매개변수: stnId\n",
    "\n",
    "지역번호\n",
    "전국: 108, 서울/경기: 109, 강원도: 105, 충청북도:131, 충청남도: 133, 전라북도:146\n",
    "전라남도: 156, 경상북도: 143, 경상남도: 159, 제주도: 184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"utf-8\" ?>\\r\\n<rss version=\"2.0\">\\r\\n<channel>\\r\\n<title>\\xea\\xb8\\xb0\\xec\\x83\\x81\\xec\\xb2\\xad \\xec\\x9c\\xa1\\xec\\x83\\x81 \\xec\\xa4\\x91'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "api = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "#encode parameter to url\n",
    "values = {'stnId': '108'}\n",
    "params = parse.urlencode(values)\n",
    "#요청 url로 전환\n",
    "url = api + \"?\" + params\n",
    "data = req.urlopen(url).read()\n",
    "text = data.decode(\"utf-8\")\n",
    "print(data[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##매개변수를 명령줄에서 지정하기\n",
    "*sys.argv가 핵심! 아래 코드는 파일로 cmd에서 실행시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=-f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "#명령줄 매개변수 추출\n",
    "if len(sys.argv) <= 1:\n",
    "    print(\"USAGE: add <Region Number>\")\n",
    "    sys.exit()\n",
    "    \n",
    "#명령줄 첫 부분이 되는 regionNum\n",
    "#예를 들어 \"python file.py 108\"이면 sys.argv[0]은 file.py, [1]은 108.\n",
    "regionNum = sys.argv[1]\n",
    "api = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "values = {'stnId': regionNum}\n",
    "params = parse.urlencode(values)\n",
    "url = api + \"?\" + params\n",
    "print(\"url=\", url)\n",
    "\n",
    "#data download\n",
    "data = req.urlopen(url).read()\n",
    "text = data.decode(\"utf-8\")\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#BeautifulSoup으로 스크레이핑 (추출)하기\n",
    "\n",
    "BeatifulSoup은 html, xml parser라고 생각하면 됨. 자체는 웹에 접근하는 기능을 갖춘 것은 아님.\n",
    "Anaconda3로 Python 개발환경을 구축한 경우 이미 보유하고 있을 것임 아닌 경우 pip로 설치."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html><body>\n",
      "<h1>스크레이핑이란</h1>\n",
      "<p>웹 페이지를 분석하는 것</p>\n",
      "<p>원하는 부분을 추출하는 것 </p>\n",
      "</body></html>\n",
      "\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "#toy hml example\n",
    "\n",
    "toy_example = \"\"\"\n",
    "<html><body>\n",
    "    <h1>스크레이핑이란</h1>\n",
    "    <p>웹 페이지를 분석하는 것</p>\n",
    "    <p>원하는 부분을 추출하는 것 </p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = bs(toy_example, 'html.parser')\n",
    "print(soup)\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##원하는 부분 tree로 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 스크레이핑이란\n",
      "p1 = 웹 페이지를 분석하는 것\n",
      "p2 = 원하는 부분을 추출하는 것 \n"
     ]
    }
   ],
   "source": [
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling #next_sibiling 한번하면 줄바꿈 or 공백이 출력됨\n",
    "\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p1 = \" + p1.string)\n",
    "print(\"p2 = \" + p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##원하는 부분 id로 접근하기 with find method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title=test test \n",
      "#body=웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "toy_example2 = \"\"\"\n",
    "<html>\n",
    "    <header>babo\n",
    "    <p id=\"title\">test test </p>\n",
    "    </header>\n",
    "    <body>\n",
    "    <h1 id=\"title\">스크레이핑이란</h1>\n",
    "    <p id =\"body\">웹 페이지를 분석하는 것</p>\n",
    "    <p>원하는 부분을 추출하는 것 </p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = bs(toy_example2, 'html.parser')\n",
    "title = soup.header.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "print(\"#title=\" + title.string)\n",
    "print(\"#body=\" + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##find_all() method로 여러개 요소 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver >> http://www.naver.com\n",
      "daum >> http://www.daum.com\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <ul>\n",
    "        <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "        <li><a href=\"http://www.daum.com\">daum</a></li>\n",
    "    </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html, 'html.parser')\n",
    "links = soup.find_all(\"a\")\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">>\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "다 class의 instance화 되어있으므로 a.attrs와 같은 식으로 접근."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##DOM(Document Object Model): xml이나 html 요소에 접근하는 구조임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "soup = bs(\"<p><a href='a.html'>test</a></p>\", \"html.parser\")\n",
    "#prettify()로 잘 파싱 되었는지 확인\n",
    "p1 = bs(html, 'html.parser').prettify()\n",
    "print(type(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<class 'dict'>\n",
      "True\n",
      "a.html\n"
     ]
    }
   ],
   "source": [
    "a = soup.p.a\n",
    "print(type(a))\n",
    "print(type(a.attrs))\n",
    "print('href' in a.attrs)\n",
    "print(a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##urlopen()과 BeautifulSoup 조합하기.\n",
    "urlopen()으로 html을 가져와서 Beautiful Soup으로 파싱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "장마전선의 영향으로 15일은 전국 대부분, 16일은 중부지방에 비가 오겠습니다. <br / ...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = req.urlopen(url)\n",
    "soup = bs(res, 'html.parser')\n",
    "title = soup.find(\"title\").string\n",
    "wf = soup.find(\"wf\").string\n",
    "print(title)\n",
    "print(wf[0:50], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##CSS 선택자 사용하기\n",
    "JQuery처럼 CSS 선택자 지정을 통해서 원하는 요소 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 위키북스 도서\n",
      "[<li>유니티 게임 이펙트 입문</li>, <li>스위프트로 시작하는 아이폰 앱 개발</li>, <li>모던 웹사이트 디자인</li>]\n",
      "li = 유니티 게임 이펙트 입문\n",
      "li = 스위프트로 시작하는 아이폰 앱 개발\n",
      "li = 모던 웹사이트 디자인\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id =\"meigen\">\n",
    "    <h1>위키북스 도서</h1>\n",
    "    <ul class=\"items\">\n",
    "        <li>유니티 게임 이펙트 입문</li>\n",
    "        <li>스위프트로 시작하는 아이폰 앱 개발</li>\n",
    "        <li>모던 웹사이트 디자인</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = bs(html, \"html.parser\")\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(\"h1 =\", h1)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "print(li_list)\n",
    "for li in li_list:\n",
    "    print(\"li =\", li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##네이버 금융에서 환율정보 가져오기\n",
    "url = \"http://info.finance.naver.com/marketindex\" <- tex에서 그림 삽입으로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/krw =1,154.30\n",
      "usd/krw =1,154.30\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://info.finance.naver.com/marketindex\"\n",
    "res = req.urlopen(url)\n",
    "soup = bs(res, \"html.parser\")\n",
    "price1 = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw =\" + price1)\n",
    "\n",
    "#price2의 경우 웹 페이지 요소검사에서 직접 가져온 css selector\n",
    "price2 = soup.select_one(\"#exchangeList > li.on > a.head.usd > div > span.value\").string\n",
    "print(\"usd/krw =\" + price2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*CSS 선택자에 대해서는 3절에서 더 자세하게 알아볼 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#CSS 선택자\n",
    "\n",
    "BeautifulSoup에서 선택자 관계 or 선택자 속성을 기반으로 CSS 선택은 가능하나 \n",
    "위치 또는 상태 지정서식은 4.5.1 기준으로 nth-of-type(n)을 제외하면 작동 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##나무위키에서 윤동주 작품 목록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《새 명동》\n",
      "《서시(序詩)》\n",
      "《또 다른 고향》\n",
      "《별 헤는 밤》\n",
      "None\n",
      "《사진판 윤동주 자필 시고전집》\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as req\n",
    "\n",
    "#위키피디아 윤동주 페이지\n",
    "url = \"https://ko.wikipedia.org/wiki/%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "soup = bs(res, 'html.parser')\n",
    "a_list = soup.select(\"#mw-content-text > div > ul > li\")\n",
    "for a in a_list[0:10]:\n",
    "    print(a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##추출 연습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n"
     ]
    }
   ],
   "source": [
    "books = \"\"\"\n",
    "<ul id = \"bible\">\n",
    "  <li id=\"ge\">Genesis</li>\n",
    "  <li id=\"ex\">Exodus</li>\n",
    "  <li id=\"le\">Leviticus</li>\n",
    "  <li id=\"nu\">Numbers</li>\n",
    "  <li id=\"de\">Deuteronomy</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "soup = bs(books, \"html.parser\")\n",
    "\n",
    "#CSS 선택자 이용 8가지 방법\n",
    "sel = lambda q: print(soup.select_one(q).string)\n",
    "sel(\"#nu\")\n",
    "sel(\"li#nu\")\n",
    "sel(\"ul > li#nu\")\n",
    "sel(\"#bible #nu\")\n",
    "sel(\"#bible > #nu\")\n",
    "sel(\"ul#bible > li#nu\")\n",
    "sel(\"li[id='nu']\")\n",
    "sel(\"li:nth-of-type(4)\")\n",
    "\n",
    "print(soup.select(\"li\")[3].string)\n",
    "print(soup.find_all(\"li\")[3].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##조금 더 복잡한 예시\n",
    "*아보카도를 추출해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n",
      "아보카도\n"
     ]
    }
   ],
   "source": [
    "fruit_vegetable = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<div id=\"main-goods\" role=page\">\n",
    " <h1>과일과 야채</h1>\n",
    " <ul id=\"fruit-list\">\n",
    "   <li class=\"red green\" data-lo=\"ko\">사과</li>\n",
    "   <li class=\"purple\" data-lo=\"us\">포도</li>\n",
    "   <li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
    "   <li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
    " </ul>\n",
    " <ul id=\"veget-list\">\n",
    "    <li class=\"white green\" data-lo=\"ko\">무</li>\n",
    "    <li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
    "    <li class=\"black\" data-lo=\"ko\">가지</li>\n",
    "    <li class=\"black\" data-lo=\"us\">아보카도</li>\n",
    "    <li class=\"white\" data-lo=\"ko\">연근</li>\n",
    " </ul>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = bs(fruit_vegetable, \"html.parser\")\n",
    "#CSS 선택자 활용하기\n",
    "print(soup.select_one(\"li:nth-of-type(8)\").string)\n",
    "print(soup.select_one(\"#veget-list > li:nth-of-type(4)\").string)\n",
    "print(soup.select(\"#veget-list > li[data-lo='us']\")[1].string)\n",
    "print(soup.select(\"#veget-list > li.black\")[1].string)\n",
    "\n",
    "#find로 여러 조건 동시에 집어 넣어서 추출\n",
    "condition = {\"data-lo\":\"us\", \"class\":\"black\"}\n",
    "print(soup.find(\"li\", condition).string)\n",
    "\n",
    "#find 연속 사용 \n",
    "print(soup.find(id=\"veget-list\").find(\"li\", condition).string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##find_all()과 정규식 사용하여 http 링크 추출하기\n",
    "BeautifulSoup에서 정규식을 활용할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 http://www.naver.com\n",
      "구글 http://www.google.com\n",
      "다음 http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "    <li><a href=\"http://www.naver.com\">네이버</li>\n",
    "    <li><a href=\"http://www.google.com\">구글</li>\n",
    "    <li><a href=\"http://www.daum.net\">다음</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html, 'html.parser')\n",
    "li = soup.find_all(href=re.compile(r\"^http://\"))\n",
    "for e in li:\n",
    "    print(e.string, e.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#링크에 있는 것을 한꺼번에 내려받기\n",
    "\n",
    "링크를 재귀적으로 다운 받아보자.\n",
    "만야겡 a태그 링크 대상이 상대 경로인 경우는 추가 처리가 필요하기 때문.\n",
    "\n",
    "목표: https://docs.python.org/3.5/library/ 에 있는 html 다 받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##상대경로를 전개하기 - URL join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- 단순히 string에서 \"+\" 연산자 사용하는 것보다 나음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/html/b.html\n",
      "http://example.com/html/sub/c.html\n",
      "http://example.com/index.html\n",
      "http://example.com/img/hoge.png\n",
      "http://example.com/css/hoge.css\n",
      "http://otherExample.com/wiki\n",
      "http://anotherExample.com/wiki\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "#urljoin(base, path) 형식\n",
    "\n",
    "base = \"http://example.com/html/a.html\"\n",
    "print(urljoin(base, \"b.html\"))\n",
    "print(urljoin(base, \"sub/c.html\"))\n",
    "\n",
    "#../를 통해 한 단계 올라갈 수 있음\n",
    "print(urljoin(base, \"../index.html\"))\n",
    "print(urljoin(base, \"../img/hoge.png\"))\n",
    "print(urljoin(base, \"../css/hoge.css\"))\n",
    "\n",
    "#뒤에 path가 full url인 경우는 path만 리턴\n",
    "print(urljoin(base, \"http://otherExample.com/wiki\"))\n",
    "print(urljoin(base, \"//anotherExample.com/wiki\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##파이썬 메뉴얼 재귀적으로 다운받기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/j/Documents/lecture/2017su/DeepLearning/_sandbox/_ch01\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
